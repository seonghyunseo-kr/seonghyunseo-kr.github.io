---
layout: post
title: "Study Notes: Batch Normalization"
date: 2026-01-14
tags: [machine-learning, study]
style: border
color: primary
comments: false
description: "A practical recap of BatchNorm: what it does, why it works, and common pitfalls."
toc: true
---

## Goal
- Understand what Batch Normalization changes during training and inference
- Know when BatchNorm helps/hurts in practice

## Key Concepts
- **Internal covariate shift** (original motivation)
- **Normalization + learnable affine parameters** ($$\gamma, \beta$$)
- Difference between **train-time batch stats** vs **inference-time running stats**

## Worked Example (High-level)
Given activations $$x$$ in a mini-batch:
- $$\mu_B = \frac{1}{m}\sum_{i=1}^m x_i$$
- $$\sigma_B^2 = \frac{1}{m}\sum_{i=1}^m (x_i - \mu_B)^2$$
- $$\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}$$
- $$y_i = \gamma \hat{x}_i + \beta$$

## Implementation Notes
- Small batch size can make BN noisy/unstable â†’ consider LayerNorm/GroupNorm
- In PyTorch, remember `model.train()` vs `model.eval()`
- When fine-tuning, freezing BN stats can matter depending on domain shift

## Summary
- BN stabilizes training and often enables higher learning rates
- Behavior differs between training and inference because of running averages
- Alternatives (LN/GN) can be better for transformers/small batches

## References
- Ioffe & Szegedy, 2015
- PyTorch docs: BatchNorm layers